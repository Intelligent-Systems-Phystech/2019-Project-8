{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_read = open(\"../data/WISDM/WISDM_ar_v1.1_raw.txt\", \"r\")\n",
    "f_write = open(\"../data/WISDM/WISDM_ar_v1.1_raw_cleared.txt\", \"w\")\n",
    "for string in f_read.readlines():\n",
    "    if string[-1] == '\\n':\n",
    "        string = string[:-1]\n",
    "    if len(string) > 0:\n",
    "        string_list = string.split(';')\n",
    "        if len(string_list) > 2:\n",
    "            for row in string_list[:2]:\n",
    "                words = row.split(',')\n",
    "                if len(words) > 5:\n",
    "                    if len(words[5]) > 0:\n",
    "                        f_write.write(\"%s,%s,%s,%s,%s,%s\\n\" % (words[0], words[1], \n",
    "                                                               words[2], words[3], \n",
    "                                                               words[4], words[5]))\n",
    "        else:\n",
    "            words = string_list[0].split(',')\n",
    "            if len(words) > 5:\n",
    "                if len(words[5]) > 0:\n",
    "                    f_write.write(\"%s,%s,%s,%s,%s,%s\\n\" % (words[0], words[1], \n",
    "                                                           words[2], words[3], \n",
    "                                                           words[4], words[5]))\n",
    "f_read.close()\n",
    "f_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wisdm = pd.read_table(\"../data/WISDM/WISDM_ar_v1.1_raw_cleared.txt\", delimiter=',', header=None)\n",
    "data_wisdm.columns = ['id_user', 'activity', 'timestamp', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us construct 10 seconds time series segments.\n",
    "* each time series should be from one user and one type of activity;\n",
    "* in the time series timestamp shouldn't differ more then 0.2 second (empirical rule, in ideal all timestamp should differ on 50 ms = 0.05 second)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_candidate(candidate, data_type, threshold=2.*1e8):\n",
    "    if data_type == \"USCHAD\":\n",
    "        threshold = 0.\n",
    "    tsp = np.array(candidate['timestamp'])\n",
    "    diffs = tsp[1:] - tsp[:-1]\n",
    "    \n",
    "    return np.sum(diffs > threshold) == 0\n",
    "\n",
    "def get_time_series(accelerations, data_type, nb=200):\n",
    "    accelerations.index = [i for i in range(len(accelerations))]\n",
    "    TS = []\n",
    "    st = 0\n",
    "    fi = st + nb\n",
    "    while fi < len(accelerations):\n",
    "        candidate = accelerations.loc[[st + i for i in range(nb)], :]\n",
    "        if check_candidate(candidate, data_type):\n",
    "            TS.append([np.array(candidate['x']), \n",
    "                       np.array(candidate['y']), \n",
    "                       np.array(candidate['z'])])\n",
    "        st = fi\n",
    "        fi += nb\n",
    "    \n",
    "    return TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(data, df):\n",
    "    classes = list(set(data['activity']))\n",
    "    for activity in classes:\n",
    "        nb = np.sum(df['activity'] == classes.index(activity))\n",
    "        print(\"{:<20}{:<9d}{:<5.2f} %\".format(activity, nb, 100. * nb / df.shape[0]))\n",
    "    print(\"\")\n",
    "    print(\"Number of objects: {:d}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_matrix(data, data_type, get_feature_names, get_features, params=[]):\n",
    "    \n",
    "    classes = list(set(data['activity']))\n",
    "    feature_names = get_feature_names(params)\n",
    "    df = pd.DataFrame(columns=['activity']+feature_names) \n",
    "\n",
    "    id_range = np.unique(np.array(data['id_user']))\n",
    "    for id_user in id_range:\n",
    "        for activity in classes:\n",
    "            mask = (data.loc[:, 'id_user'] == id_user) & (data.loc[:, 'activity'] == activity)\n",
    "            accelerations = data.loc[mask, ['timestamp', 'x', 'y', 'z']].copy()\n",
    "            TS = get_time_series(accelerations, data_type, nb=200)\n",
    "            for ts in TS:\n",
    "                features = get_features(ts, params)\n",
    "                df.loc[len(df), :] = [classes.index(activity)] + features\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is the following: we will consider 10 seconds time series (or 200 points of measurements) and calculate 40 features:\n",
    "* ```[3]``` - mean acceleration of each axis;\n",
    "* ```[3]``` - std of acceleration of each axis;\n",
    "* ```[3]``` - mean absolute deviation of acceleration of each axis;\n",
    "* ```[1]``` - mean acceleration;\n",
    "* ```[30]``` - distribution of time series values of each axis. First of all we calculate min and max of each component ($X, Y, Z$) from the whole interval. Then we divide the range of values of each component into 10 equal intervals and calculate on each each interval the percent of values that are in it (in the corresponding interval).  \n",
    "\n",
    "And apply LogisticRegression and SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expert_names(params):\n",
    "    feature_names = ['avg_x', 'avg_y', 'avg_z', \n",
    "                     'std_x', 'std_y', 'std_z', \n",
    "                     'abs_x', 'abs_y', 'abs_z', 'mean']\n",
    "    for i in range(10):\n",
    "        name = str(i) + '_'\n",
    "        feature_names += [name + 'x', name + 'y', name + 'z']\n",
    "        \n",
    "    return feature_names\n",
    "\n",
    "def get_expert_features(ts, params):\n",
    "    x = ts[0]\n",
    "    y = ts[1]\n",
    "    z = ts[2]\n",
    "    n = x.shape[0]\n",
    "    features = []\n",
    "    features.append(x.mean())\n",
    "    features.append(y.mean())\n",
    "    features.append(z.mean())\n",
    "    features.append(x.std())\n",
    "    features.append(y.std())\n",
    "    features.append(z.std())\n",
    "    features.append(np.abs(x - x.mean()).mean())\n",
    "    features.append(np.abs(y - y.mean()).mean())\n",
    "    features.append(np.abs(z - z.mean()).mean())\n",
    "    features.append((x+y+z).mean() / 3.)\n",
    "    x_range = np.linspace(x.min(), x.max(), 11)\n",
    "    y_range = np.linspace(y.min(), y.max(), 11)\n",
    "    z_range = np.linspace(z.min(), z.max(), 11)\n",
    "    for i in range(10):\n",
    "        features.append(1. * np.sum((x_range[i] <= x) & (x < x_range[i+1])) / n)\n",
    "        features.append(1. * np.sum((y_range[i] <= y) & (y < y_range[i+1])) / n)\n",
    "        features.append(1. * np.sum((z_range[i] <= z) & (z < z_range[i+1])) / n)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_expert_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_expert_names, get_expert_features)\n",
    "df_expert_wisdm.to_csv(\"../data/features/expert_wisdm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_expert_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_expert_names, get_expert_features)\n",
    "#df_expert_uschad.to_csv(\"../data/features/expert_uschad.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autoregressive_names(params):\n",
    "    n = params[0]\n",
    "    feature_names = []\n",
    "    for ax in ['x', 'y', 'z']:\n",
    "        feature_names += ['intercept_' + ax]\n",
    "        for i in range(n):\n",
    "            feature_names += ['coef_' + str(i) + '_' + ax]\n",
    "            \n",
    "    return feature_names\n",
    "\n",
    "def get_autoregressive_features(ts, params):\n",
    "    n = params[0]\n",
    "    x = ts[0]\n",
    "    y = ts[1]\n",
    "    z = ts[2]\n",
    "    m = x.shape[0]\n",
    "    features = []\n",
    "    X = np.zeros([m-n, n])\n",
    "    Y = np.zeros(m-n)\n",
    "    for axis in [x, y, z]:\n",
    "        for i in range(m-n):\n",
    "            X[i, :] = axis[i:i+n]\n",
    "            Y[i] = axis[i+n]\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X, Y)\n",
    "        features.append(lr.intercept_)\n",
    "        features.extend(lr.coef_)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = [20]\n",
    "df_ar_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_autoregressive_names,\n",
    "                                 get_autoregressive_features, params)\n",
    "df_ar_wisdm.to_csv(\"../data/features/ar_wisdm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#params = [20]\n",
    "#df_ar_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_autoregressive_names,\n",
    "#                                  get_autoregressive_features, params)\n",
    "#df_ar_uschad.to_csv(\"../data/features/ar_uschad.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrum analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrum_names(params):\n",
    "    n = params[0]\n",
    "    feature_names = []\n",
    "    for ax in ['x', 'y', 'z']:\n",
    "        for i in range(n):\n",
    "            feature_names += ['eigv_' + str(i) + '_' + ax]\n",
    "            \n",
    "    return feature_names\n",
    "\n",
    "def get_spectrum_features(ts, params):\n",
    "    n = params[0]\n",
    "    x = ts[0]\n",
    "    y = ts[1]\n",
    "    z = ts[2]\n",
    "    m = x.shape[0]\n",
    "    features = []\n",
    "    X = np.zeros([m-n, n])\n",
    "    Y = np.zeros(m-n)\n",
    "    for axis in [x, y, z]:\n",
    "        for i in range(m-n):\n",
    "            X[i, :] = axis[i:i+n]\n",
    "        h = sc.linalg.svd(X.T.dot(X), compute_uv=False, overwrite_a=True)\n",
    "        features.extend(h)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [20]\n",
    "df_ssa_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_spectrum_names,\n",
    "                                  get_spectrum_features, params)\n",
    "df_ssa_wisdm.to_csv(\"../data/features/ssa_wisdm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#params = [20]\n",
    "#df_ssa_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_spectrum_names,\n",
    "#                                   get_spectrum_features, params)\n",
    "#df_ssa_uschad.to_csv(\"../data/features/ssa_uschad.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Fourier Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
