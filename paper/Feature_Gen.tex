\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
%\NOREVIEWERNOTES

\title
    [Порождение признаков с помощью локально-аппроксимирующих моделей.]
    {Порождение признаков с помощью локально-аппроксимирующих моделей.}
\author
    {Садиев~А.\,А., Фатхуллин И.\,Ф., Мотренко~А.\,П., Стрижов~В.\,В.} % основной список авторов, выводимый в оглавление
    [Садиев~А.\,А.$^1$,Фатхуллин И.\,Ф.$^1$, Мотренко~А.\,П.$^1$, Стрижов~В.\,В.$^1$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\thanks
    {Работа выполнена при финансовой поддержке РФФИ, проект \No\,00-00-00000.
   Научный руководитель:  Стрижов~В.\,В.
   Задачу поставил:  Эксперт~И.\,О.
    Консультант:  Мотренко~А.\,П.}
\email
    {sadiev.aa@phystech.edu, ilyas.fn979@gmail.com}
\organization
    {$^1$Московский физико-технический институт (МФТИ)}
\abstract
    {Рассматриваются методы классификации физической активности человека по измерениям акселерометра. Статья посвящена исследованию проблемы порождения признаков с использованием локально-аппроксимирующих моделей. В работе строится набор локально-аппроксимирующих моделей и проверяется корректность гипотезы о простоте выборки для порожденных признаков. Решается задача выбора оптимального способа порождения признаков временного ряда. В контексте данной работе предполагается метод построения метрического пространства описаний элементарных движений.
    
    

\bigskip
\textbf{Ключевые слова}: \emph {временной ряд, многоклассовая классификация, локально-аппроксимирующая модель, метрическое пространство}.}
\titleEng
    {JMLDA paper example: file jmlda-example.tex}
\authorEng
    {Author~F.\,S.$^1$, CoAuthor~F.\,S.$^2$, Name~F.\,S.$^2$}
\organizationEng
    {$^1$Organization; $^2$Organization}
\abstractEng
    {This document is an example of paper prepared with \LaTeXe\
    typesetting system and style file \texttt{jmlda.sty}.

    \bigskip
    \textbf{Keywords}: \emph{keyword, keyword, more keywords}.}
\begin{document}
\maketitle
%\linenumbers
\section{Введение}
Работа посвящена поиску оптимальных признаков для задачи классификации видов физической активности человека. Исследование проводится с целью автоматизации порождения признаков слабоструктурированных данных, таких как временные ряды. Оптимальный выбор признаков должен удовлетворять выборкам временных рядов с различными частотами. Также предлагаемый в данной работе метод должен обеспечивать минимальное расхождение в точности задачи классификации с различными множествами ответов.

Задача оптимального порождения признаков решается различными способами \cite{MotrenkoS16,KarStr16, KuzIv15,  AnPenStr18, IsZhar18, ZaPoStr16 }. В работе \cite{MotrenkoS16} выделяются фундаментальные периоды временных рядов, в \cite{KarStr16, KuzIv15} внимание уделено сегментации временного ряда различными способами. Также стоит отметить использование сплайнов в порождении признаков временнго ряда \cite{AnPenStr18}, в статье \cite{IsZhar18} предложен новый метод с использованием кубических сплайнов, которые дают гладкую кривую и приемлемое качество аппроксимации. Помимо классических методов применяются нейронные сети, а именно построение нейронной сети оптимальной структуры для решения задачи классификации. В работе \cite{ZaPoStr16} используются два алгоритма на нейронных сетях для получения решения задачи классификации.

В данной работе задача решается с помощью построения  универсальной стандарта . Он состоит из суперпозиции  локально-аппроксимирующих моделей исходной выборки. Предлагаемый метод не дает наилучшую точность среди уже имеющихся спрособов , однако является универсальным для данных с различными параметрами выборок. Однако, был создана библиотека локально-аппроксимирующих моделей, удобно используемая на практике.

Вычислительный эксперимент проводится на данных временных рядов акселерометра WISDM с целью решения задачи классификации.


\section{Постановка задачи}
Пусть задана выборка 
$\mathfrak{D}$ = z$\{(\mathbf{s}_i,y_i)|\; i=1,...,m;\; \mathbf{s}_i = [\mathbf{s}_i(1), \dots ,\mathbf{s}_i(T) ] \in \mathbf{S} \subset \mathbb{R}^{n\times m} \}$, где $\mathbf{s}_i(t) \in \mathbb{R}^n$, $ y_i \in Y$ - пространство ответов, $|Y| = K \in \mathbb{N}$, $m$ - количество элементов в выборке. Поставим задачу многоклассовой классификации временных рядов. Временные ряды  являются объектами сложной структуры. Поэтому процесс классификации разбивают на два основных этапа: первый - порождение признакового описания (создание пространства признаков), второй - решение задачи классификации. Формально задача классификации состоит в определении отображения $f: \mathbf{S} \rightarrow Y$. Отображение будем искать в виде суперпозиции: 
\begin{equation}
    f(\mathbf{s}) = g(h(\mathbf{s}), \mathbf{w})
\end{equation}
где $h: \mathbf{S} \rightarrow \Phi$. $\Phi \subset \mathbb{R}^p$ - пространство признаков, $\mathbf{w}$ - вектор параметров модели.

Чтобы определить качество работы классификатора, задается функция потерь $\mathcal{L}\left(f(\mathbf{s}_i), y_i)\right)$, выражающая величину ошибки классификации отображения $f$ на объекте $\mathbf{s_i}$ данной выборки $\mathfrak{D}$. Таким образом, для решения нашей задачи нужно найти отображение $f$, минимизирующая суммарную фунцию потерь на выборке $\mathfrak{D}$:

\begin{equation}
\mathbf{y}_{opt} = \argmin_{\mathbf{y} \in \mathbb{R}^m} \sum^m_{i  = 1}\mathcal{L}(f(\mathbf{s}_i, \mathbf{w})]
\end{equation}


Функция $f$, определенная в (1), является суперпозицией отображений $g(. , \mathbf{w})$ и $h(s)$. В данной работе исследуются свойства функций вида  $h: \mathbf{S} \rightarrow \Phi$: она порождает признаковое описание объектов $\mathbf{s}_i$ из данной выборки $\mathfrak{D}$.  Есть множество способов определить $h$, например, с помошью алгоритмов AR, DFT, SSA, SEMOR и т. д. Поэтому будем рассматривать модели $h_j \in \mathcal{H}$, где $j \in \{1, \dots, r\}$, где $r$  - количество моделей в наборе $\mathcal{H}$. Эти функции создают признаковое описание объекта $\mathbf{s}_i$ (каждая свое),  т. е.
$h_j(\mathbf{s}_i)  = \boldsymbol{\phi}^{(i j)} =[\phi_{1}^{(i j)}, \dots, \phi_{p}^{(i j)}] ^T \in \Phi$. 
%Далее возникает вопрос: как сочитать признаки, полученные различными моделями, для одного объекта. Поступим следующим образом: функция $h_1$ определяет первые $p$ компонент ( вектор $\boldsymbol{\phi}^{(i 1)}$)%
Допустим на первом этапе каким-либо образом получено подмножество $\mathcal{P} \subset \mathcal{H}$ алгоритмов из заданного набора. Подмножеству $\mathcal{P}$ соответствует признаковое описание, полученное конкатенацией признаков алгоритмов из $\mathcal{P}$. Тогда на втором этапе имеем классическую задачу многоклассовой классификации:
\begin{equation}
\mathbf{w}_{opt} = \argmin_{\mathbf{w} \in \mathbb{R}^p} \mathcal{L}[g(\mathcal{P}, \mathbf{w})]
\end{equation}
В итоге, объединяя два этапа, получаем задачу вида:

\begin{equation}
\mathbf{\mathcal{P}}_{opt} = \argmin_{\mathcal{P}\subset \mathcal{H}} \min_{\mathbf{w} \in \mathbb{R}^p}\mathcal{L}\left[g(\mathcal{P}, \mathbf{w})\right]
\end{equation}

\section{Порождение признаков}

Как было описано выше функция $h: \mathbf{S} \rightarrow \Phi$, где $\Phi \subset \mathbb{R}^p$ - пространство признаков, порождает ращлчные признаки. Стоит отметить, что мы работаем с сегментом, как с объектом. Приведем какие функции мы использовали: 

\subsection{Дискретное преобразование Фурье}

Берется временной ряд $\mathbf{s}_i \in \mathbf{S}$ и производят сегментацию: получают набор $\{\mathbf{s}^k_i\}^N_{k = 0}$, где $N$ -  количество полученных сегментов. Далее работаем с одним сегментом как с объектом: применяем к нему дискретное преобразование Фурье
\begin{equation}
f_k = \sum_{n=0}^{N'-1} s^k_i[n] e^{-\frac{2 \pi i}{N'} k n} %= \sum_{n=0}^{N'-1} s^k_i[n]\cdot \left[\cos\left(2 \pi k \frac{n}{N'}\right) - i\cdot \sin\left(2 \pi k \farc{n}{N'}\right)\right]%
, \qquad (k = 0, \dots, N'-1)
\end{equation}
$N'$ -  количество элементов в $s^k_i$. Так как полученные коэффициенты копмлексные, что не понятно как интерпретировать физически, то мы комплексное число представим в полярном виде: компоненты вектора признаков у величится в двое. Таким образом, мы получаем вектор признаков 
$\mathbf{f} = (f_1 \quad f_2 \dots f_{2N'})$.

\subsection{Статистические функции}
Берется временной ряд $\mathbf{s}_i \in \mathbf{S}$ и производят сегментацию: получают набор $\{\mathbf{s}^k_i\}^N_{k = 0}$, где $N$ -  количество полученных сегментов. Далее работаем с одним сегментом как с объектом:

\begin{itemize}
    \item Среднее значение: $\overline{m}^k_i= \farc{1}{N'}\sum^{N'}_{n = 1}\mathbf{s}^k_i[n] $
    
    \item Дисперсия: $d^k_i = \farc{1}{N'^2}\sum^{N'}_{n = 1}((\mathbf{s}^k_i[n])^2 - (\overline{m}^k_i)^2) $
    
    \item Абсолютное отклонение $\alpha^k_i = \farc{1}{N'^2}\sum^{N'}_{n = 1}(\mathbf{s}^k_i[n] - \overline{m}^k_i) $
\end{itemize}{}

Применяя эти функции к каждому сегменту, мы порождаем признаки.

\subsection{Авторегрессия}
Берется временной ряд $\mathbf{s}_i \in \mathbf{S}$ и производят сегментацию: получают набор $\{\mathbf{s}^k_i\}^N_{k = 0}$, где $N$ -  количество полученных сегментов. Далее работаем с одним сегментом как с объектом. Авторегресия учитывает предысторию, что логично использовать. Поэтому это записывается в следущем виде :

\begin{equation}
\mathbf{s}^k_{i} [t + 1] = \sum^l_{j = 1} w_j s^k_i [t - j + 1] \text{,}
\end{equation}где $l$ - количество предыдущих наблюдений ряда (сегмента), $\hat{\mathbf{w}}$ -  вектор параметров модели авторегрессии.  Формулу $(6)$ перепишем в маричном виде:

\begin{equation}
 \[ \bordermatrix{ 
&&&&\cr
& s^k_i [t - 1] & s^k_i [t - 2] & \dots  & s^k_i [t - l]  \cr 
 & s^k_i [t - 2] & s^k_i [t - 3] & \dots  & s^k_i [t - l - 1]  \cr 
 F^{\alpha \times l} = &\dots &\dots&\dots&\dots \cr
  & s^k_i [l] & s^k_i [l - 2] & \dots  & s^k_i [ 1]  \cr
  & s^k_i [l - 1] & s^k_i [l - 2] & \dots  & s^k_i [0]  \cr }
\]
\[ \bordermatrix{ 
&\cr
& s^k_i [t ] \cr 
 & s^k_i [t - 1]  \cr 
\mathbf{y}^{\alpha \times 1} = &\dots \cr
  & s^k_i [n + 1]   \cr
  & s^k_i [n]  \cr }
\]

\end{equation}

где   в роли объектов $\alpha  =  t - l + 1$ моментов из истории. Тогда чтобы найти вектор параметров данной модели нужно решить следующую задачу минимизации:

\begin{equation}
\hat{\mathbf{w}}_{opt} = \argmin_{\hat{\mathbf{w} }\in \mathbb{R}^l} \|F \hat{\mathbf{w} }  - y\|
\end{equation}Таким образом, полученным вектором параметров мы будем характеризовывать наш сегмент. 

\section{Базовый вычислительный эксперимент}
В качестве вычислительного эксперимента была выбрана задача классификации типов физической активности человека по данным с акселерометра. 

Данные WISD представляют собой трехмерные временные ряды, полученные с датчика акселерометра, причем данные размечены, но не сегментированы. Частота измерений составляет $20$ Гц. В данной выборке представлены $6$ классов: 
 sitting (225), standing (275), walking (2890), jogging (1631), upstairs (801), downstairs (657). 


\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{WISDM.jpg}
\caption{Количество измерений для каждого класса}
\end{figure}


Сегментация ряда произдодилось делением на равномерные части (сегменты).  Стандартно  количество сегментов $n = 200$. В качестве  модели классификации  рассматривались логистическая регрессия, случайный лес и  метод опорных векторов $SVM$.
\newpage 
Используя приведенные выше алгоритмы порождения признаков, мы смогли создать матрицу объект-признак , и далее использовать ее для классификации данных по 6 классам.  Приведем полученный результат:
\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{Results.jpg}
\caption{Результаты}
\end{figure}
\section{Заключение}
Желательно, чтобы этот раздел был, причём он не~должен дословно повторять аннотацию.
Обычно здесь отмечают,
каких результатов удалось добиться,
какие проблемы остались открытыми.

\bibliographystyle{plain}
\bibliography{bibliography}

%\begin{thebibliography}{1}

%\bibitem{author09anyscience}
%    \BibAuthor{Author\;N.}
%    \BibTitle{Paper title}~//
%    \BibJournal{10-th Int'l. Conf. on Anyscience}, 2009.  Vol.\,11, No.\,1.  Pp.\,111--122.
%\bibitem{myHandbook}
%    \BibAuthor{Автор\;И.\,О.}
%    Название книги.
%    Город: Издательство, 2009. 314~с.
%\bibitem{author09first-word-of-the-title}
%    \BibAuthor{Автор\;И.\,О.}
%    \BibTitle{Название статьи}~//
%    \BibJournal{Название конференции или сборника},
%    Город:~Изд-во, 2009.  С.\,5--6.
%\bibitem{author-and-co2007}
%    \BibAuthor{Автор\;И.\,О., Соавтор\;И.\,О.}
%    \BibTitle{Название статьи}~//
%    \BibJournal{Название журнала}. 2007. Т.\,38, \No\,5. С.\,54--62.
%\bibitem{bibUsefulUrl}
%    \BibUrl{www.site.ru}~---
%    Название сайта.  2007.
%\bibitem{voron06latex}
%    \BibAuthor{Воронцов~К.\,В.}
%    \LaTeXe\ в~примерах.
%    2006.
%    \BibUrl{http://www.ccas.ru/voron/latex.html}.
%\bibitem{Lvovsky03}
%    \BibAuthor{Львовский~С.\,М.} Набор и вёрстка в пакете~\LaTeX.
%    3-е издание.
%    Москва:~МЦHМО, 2003.  448~с.
%\end{thebibliography}

% Решение Программного Комитета:
%\ACCEPTNOTE
%\AMENDNOTE
%\REJECTNOTE
\end{document}
